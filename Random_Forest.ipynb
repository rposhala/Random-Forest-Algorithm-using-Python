{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOuosrItGh9W+e05A8tGHkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rposhala/Random-Forest-Algorithm-using-Python/blob/master/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eQOGxe3U8Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWvssQ_mVDHW",
        "colab_type": "text"
      },
      "source": [
        "# Random forest algorithm code using NumPy ( we can also look at decision trees generated by printing output of decisiontree(df))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPRnlX3EVEHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomForest(X_train,Y_train,X_test):\n",
        "    \n",
        "\n",
        "    Y_train = np.asarray([Y_train])\n",
        "    Y_train = np.swapaxes(Y_train,0,1)\n",
        "    df = np.append(X_train,Y_train,axis=1)\n",
        "\n",
        "    ## to calculate gini index\n",
        "    def gini(df):\n",
        "        x_unique,x_count = np.unique(df[:,-1], return_counts=True)\n",
        "        x_prob = x_count/np.sum(x_count)\n",
        "        x_gini = 1 - (np.dot(x_prob,x_prob))\n",
        "        return x_gini\n",
        "\n",
        "    ## function picks the best value to split the real valued attribute \n",
        "    def pick_the_value(df,n):\n",
        "        n_best = []\n",
        "        loss = 1000 # loss would not be more than 1 as gini is atmost 0.5\n",
        "        unique = np.sort(np.unique(df[:,n]))\n",
        "        split_values = [((unique[index]+unique[index-1])/2) for index in range(1,len(unique))]\n",
        "        if len(split_values) > 100 :\n",
        "            strip = list(range(1,100))\n",
        "            steps = np.ptp(df[:,n])/100\n",
        "            mini = np.min(df[:,n])\n",
        "            split_values = mini+(np.asarray(strip)*steps)\n",
        "\n",
        "        for i in split_values:\n",
        "            above = df[df[:,n] > i]\n",
        "            below = df[df[:,n] <= i] \n",
        "            a_gini = gini(above)\n",
        "            b_gini = gini(below)\n",
        "            a_len = len(above)\n",
        "            b_len = len(below)\n",
        "            current_loss = ((a_len/(a_len+b_len))*a_gini) + ((b_len/(a_len+b_len))*b_gini)\n",
        "            \n",
        "            if current_loss < loss:\n",
        "                loss = current_loss\n",
        "                n_best = [i,loss,above,below,n]\n",
        "        return n_best\n",
        "\n",
        "    ## picks the best node(attribute) to split\n",
        "    def decision_node(df):\n",
        "        node_split = []\n",
        "        par_loss = 1000\n",
        "        col_no = df.shape[1] - 1\n",
        "        par_list = np.random.choice(col_no,int(np.floor(np.sqrt(col_no))),replace=False)\n",
        "        for i in par_list:\n",
        "            i_best = pick_the_value(df,i)\n",
        "\n",
        "            if len(i_best)!=0 :\n",
        "                if i_best[1] < par_loss:\n",
        "                    par_loss = i_best[1]\n",
        "                    node_split = i_best\n",
        "        return node_split\n",
        "\n",
        "    ## displaying the decision tree with tree pruning option (we can decide till which height the tree can go before stop, it decides the label based on the majority)\n",
        "    def decisiontree(df):#,c = 0, m = 3):\n",
        "        x_unique = np.unique(df[:,-1])\n",
        "        if len(x_unique) == 1:# or c == m:\n",
        "            return x_unique[0]\n",
        "        else :\n",
        "            # c+=1\n",
        "            split = decision_node(df)\n",
        "            col_no = split[4]\n",
        "            value = split[0]\n",
        "            df_above = split[2]\n",
        "            df_below = split[3]\n",
        "            condition = \"{} <= {}\".format(col_no,value)\n",
        "            decision_tree = {condition : []}\n",
        "            true = decisiontree(df_below)#,c,m)\n",
        "            false = decisiontree(df_above)#,c,m)\n",
        "\n",
        "            decision_tree[condition].append(true)\n",
        "            decision_tree[condition].append(false)\n",
        "\n",
        "            return decision_tree\n",
        "\n",
        "    ## bootstrapping the datasets to generate multiple decision trees \n",
        "    def bootstrap_decision_tree(df):\n",
        "        list_bootstrapped_tree = []\n",
        "        n = 15 ## number of bootstrapped datasets need to be created\n",
        "        for i in range(n):\n",
        "            index = np.random.choice(len(df),len(df),replace=True)\n",
        "            list_bootstrapped_tree.append(decisiontree(df[index]))\n",
        "        return list_bootstrapped_tree\n",
        "\n",
        "    ## test sample is being passed through the decision tree and label is assigned\n",
        "    def classify(test_sample,tree):\n",
        "        condition = list(tree.keys())[0]\n",
        "        column_number = condition.split()[0]\n",
        "        value = condition.split()[2]\n",
        "        if test_sample[int(column_number)] <= float(value):\n",
        "            label = tree[condition][0]\n",
        "        else :\n",
        "            label = tree[condition][1]\n",
        "        if type(label) == dict:\n",
        "            sub_tree = label\n",
        "            return classify(test_sample,sub_tree)\n",
        "        else :\n",
        "            return label\n",
        "\n",
        "    ## label for a test sample is picked based on majority among the labels generated from bootstrapped decision trees for that test sample\n",
        "    def predict(x_test,list_bootstrapped_tree):\n",
        "        y_pred = []#np.asarray([])\n",
        "        for test in x_test:\n",
        "            label_list = []\n",
        "            for i in list_bootstrapped_tree:\n",
        "                label_list.append(classify(test,i))\n",
        "            unique_labels,count = np.unique(label_list,return_counts=True)\n",
        "            y_pred.append(unique_labels[np.argmax(count)])\n",
        "        return y_pred\n",
        "    list_bootstrapped_tree = bootstrap_decision_tree(df)\n",
        "    y_pred = predict(X_test,list_bootstrapped_tree)\n",
        "\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WISPdzu3mjfX",
        "colab_type": "text"
      },
      "source": [
        "# Function defined to calculate Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoyyUKZxmZ-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ConfusionMatrix(y_true,y_pred):\n",
        "    \n",
        "    \n",
        "    classes = 11\n",
        "    modified_list = ((y_true-1)*classes) + (y_pred-1)\n",
        "    squared_no_of_classes = classes**2\n",
        "    confusion_matrix = np.histogram(modified_list, bins=np.arange(squared_no_of_classes+1))[0]\n",
        "    confusion_matrix = confusion_matrix.reshape(classes,classes)\n",
        "    return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tne9HN_3mr7n",
        "colab_type": "text"
      },
      "source": [
        "# Function defined to calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOKijgoYmo-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Accuracy(y_true,y_pred):\n",
        "\n",
        "    nppred = np.asarray(y_pred)\n",
        "    c = y_true - nppred\n",
        "    misclass = np.count_nonzero(c)\n",
        "    test_len = len(y_true)\n",
        "    accuracy = 1 - (misclass/test_len)\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud1YFohDmwTD",
        "colab_type": "text"
      },
      "source": [
        "# Function defined to calculate Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3a5V3dSmrI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Recall(y_true,y_pred):\n",
        "\n",
        "    confusion_matrix = ConfusionMatrix(y_true,y_pred)\n",
        "    macro_recall = np.sum(np.divide(np.diag(confusion_matrix),np.sum(confusion_matrix,axis=1)))/len(confusion_matrix)\n",
        "    return macro_recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TkwY4Idm6nQ",
        "colab_type": "text"
      },
      "source": [
        "# Function defined to calculate Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knkbWSVhm8_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Precision(y_true,y_pred):\n",
        "\n",
        "    confusion_matrix = ConfusionMatrix(y_true,y_pred)\n",
        "    macro_precision = np.sum(np.divide(np.diag(confusion_matrix),np.sum(confusion_matrix,axis=0)))/len(confusion_matrix)\n",
        "    return macro_precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8rYFL0pnAFS",
        "colab_type": "text"
      },
      "source": [
        "# Loading a dataset using Pandas to test the Random Forest algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2LyAADfnDKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.seed(4563)\n",
        "data = pd.read_csv(\"data.csv\", header = None , skiprows = 1)\n",
        "dataframe = pd.DataFrame()\n",
        "dataframe = pd.DataFrame(data)\n",
        "Y = dataframe.pop(dataframe.columns[-1])\n",
        "ind = np.random.choice(len(dataframe),len(dataframe)*8//10,replace=False)\n",
        "df = np.asarray(dataframe)\n",
        "label = np.asarray(Y)\n",
        "X_train = df[ind]\n",
        "X_test = np.delete(df,ind,axis = 0)\n",
        "Y_train = label[ind]\n",
        "Y_test = np.delete(label,ind,axis = 0)\n",
        "# train_len = len(x_train)\n",
        "# test_len = len(x_test)\n",
        "# col_len = x_train.shape[1]\n",
        "x_train_norm = (X_train - np.mean(X_train,axis = 0)[np.newaxis,:])/np.std(X_train,axis=0)[np.newaxis,:]\n",
        "x_test_norm = (X_test - np.mean(X_test,axis = 0)[np.newaxis,:])/np.std(X_test,axis=0)[np.newaxis,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhgNmykpnuGF",
        "colab_type": "text"
      },
      "source": [
        "# Displaying calculated Accuracy, Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4XOCvUnrTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rf = RandomForest(X_train,Y_train,X_test)\n",
        "print(\"Accuracy :\",Accuracy(Y_test,y_pred_rf))\n",
        "print(\"Precision :\",Precision(Y_test,y_pred_rf))\n",
        "print(\"Recall\",Recall(Y_test,y_pred_rf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dM_pLFLoxWt",
        "colab_type": "text"
      },
      "source": [
        "*************************** The end ***************************\n",
        "\n",
        "..\n",
        "\n",
        ".."
      ]
    }
  ]
}
